{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import opensmile\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data for RAVDESS (recursive)\n",
    "def load_audio_files_ravdess(dataset_path):\n",
    "    audio_files = []\n",
    "    labels = []\n",
    "    for root, _, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                emotion_code = int(file.split(\"-\")[2])  # Extract emotion from filename\n",
    "                labels.append(emotion_code)\n",
    "                audio_files.append(os.path.join(root, file))\n",
    "    print(f\"Found {len(audio_files)} audio files in total.\")\n",
    "    return audio_files, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2880 audio files in total.\n"
     ]
    }
   ],
   "source": [
    "# Emotion Mapping for RAVDESS\n",
    "def map_emotions_ravdess(labels):\n",
    "    emotion_dict = {\n",
    "        1: 'neutral', 2: 'calm', 3: 'happy', 4: 'sad',\n",
    "        5: 'angry', 6: 'fearful', 7: 'disgust', 8: 'surprised'\n",
    "    }\n",
    "    return [emotion_dict[label] for label in labels]\n",
    "\n",
    "# Feature Extraction using OpenSMILE\n",
    "def extract_features(file_path):\n",
    "    smile = opensmile.Smile(\n",
    "        feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "        feature_level=opensmile.FeatureLevel.Functionals\n",
    "    )\n",
    "    features = smile.process_file(file_path)\n",
    "    return features.values.flatten()\n",
    "\n",
    "# Feature Selection using XGBoost\n",
    "def feature_selection(X, y):\n",
    "    xgb_model = xgb.XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss')\n",
    "    xgb_model.fit(X, y)\n",
    "    feature_importances = xgb_model.feature_importances_\n",
    "    top_features = np.argsort(feature_importances)[-50:]\n",
    "    return X[:, top_features]\n",
    "\n",
    "# --------- Load and Process RAVDESS Dataset ---------\n",
    "dataset_path = \"C:/Users/samhi/OneDrive/문서/College/s6/Speech Processing/Endsem/Final codes/ravdees\"  # Update if needed\n",
    "\n",
    "audio_files, labels = load_audio_files_ravdess(dataset_path)\n",
    "labels_mapped = map_emotions_ravdess(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2880/2880 [14:20<00:00,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features from 2880 files.\n",
      "Skipped 0 files due to errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Robust Feature Extraction\n",
    "X = []\n",
    "y_clean = []\n",
    "failed_files = []\n",
    "\n",
    "for file, label in tqdm(zip(audio_files, labels_mapped), total=len(audio_files)):\n",
    "    try:\n",
    "        features = extract_features(file)\n",
    "        if features.size == 0:\n",
    "            raise ValueError(\"Empty feature vector\")\n",
    "        X.append(features)\n",
    "        y_clean.append(label)\n",
    "    except Exception as e:\n",
    "        failed_files.append((file, str(e)))\n",
    "\n",
    "print(f\"Extracted features from {len(X)} files.\")\n",
    "print(f\"Skipped {len(failed_files)} files due to errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:16:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-04-05 23:22:26,088] A new study created in memory with name: no-name-4e8a0cce-f4b5-4c2f-b9ea-fbaa63425ec0\n",
      "[I 2025-04-05 23:23:02,167] Trial 0 finished with value: 0.390625 and parameters: {'lstm_units': 74, 'dropout_rate': 0.37880759152782395, 'batch_size': 32}. Best is trial 0 with value: 0.390625.\n",
      "[I 2025-04-05 23:24:22,407] Trial 1 finished with value: 0.4583333432674408 and parameters: {'lstm_units': 155, 'dropout_rate': 0.23073275779485444, 'batch_size': 16}. Best is trial 1 with value: 0.4583333432674408.\n",
      "[I 2025-04-05 23:25:21,310] Trial 2 finished with value: 0.3993055522441864 and parameters: {'lstm_units': 243, 'dropout_rate': 0.2118050107164003, 'batch_size': 64}. Best is trial 1 with value: 0.4583333432674408.\n",
      "[I 2025-04-05 23:25:58,187] Trial 3 finished with value: 0.4166666567325592 and parameters: {'lstm_units': 165, 'dropout_rate': 0.3325164209765772, 'batch_size': 64}. Best is trial 1 with value: 0.4583333432674408.\n",
      "[I 2025-04-05 23:26:52,304] Trial 4 finished with value: 0.4305555522441864 and parameters: {'lstm_units': 125, 'dropout_rate': 0.4502053414793553, 'batch_size': 16}. Best is trial 1 with value: 0.4583333432674408.\n",
      "[I 2025-04-05 23:28:11,095] Trial 5 finished with value: 0.4461805522441864 and parameters: {'lstm_units': 227, 'dropout_rate': 0.28579038491164216, 'batch_size': 32}. Best is trial 1 with value: 0.4583333432674408.\n",
      "[I 2025-04-05 23:29:16,482] Trial 6 finished with value: 0.421875 and parameters: {'lstm_units': 155, 'dropout_rate': 0.250680783230457, 'batch_size': 16}. Best is trial 1 with value: 0.4583333432674408.\n",
      "[I 2025-04-05 23:30:12,398] Trial 7 finished with value: 0.4513888955116272 and parameters: {'lstm_units': 122, 'dropout_rate': 0.3097973680235986, 'batch_size': 16}. Best is trial 1 with value: 0.4583333432674408.\n",
      "[I 2025-04-05 23:31:40,361] Trial 8 finished with value: 0.4809027910232544 and parameters: {'lstm_units': 231, 'dropout_rate': 0.3582568679621659, 'batch_size': 16}. Best is trial 8 with value: 0.4809027910232544.\n",
      "[I 2025-04-05 23:32:25,712] Trial 9 finished with value: 0.3854166567325592 and parameters: {'lstm_units': 194, 'dropout_rate': 0.4530767667865598, 'batch_size': 64}. Best is trial 8 with value: 0.4809027910232544.\n",
      "[I 2025-04-05 23:33:47,781] Trial 10 finished with value: 0.4409722089767456 and parameters: {'lstm_units': 214, 'dropout_rate': 0.38954371340446664, 'batch_size': 16}. Best is trial 8 with value: 0.4809027910232544.\n",
      "[I 2025-04-05 23:35:06,874] Trial 11 finished with value: 0.4548611044883728 and parameters: {'lstm_units': 183, 'dropout_rate': 0.20248979998812885, 'batch_size': 16}. Best is trial 8 with value: 0.4809027910232544.\n",
      "[I 2025-04-05 23:37:11,727] Trial 12 finished with value: 0.4982638955116272 and parameters: {'lstm_units': 253, 'dropout_rate': 0.3925523579584986, 'batch_size': 16}. Best is trial 12 with value: 0.4982638955116272.\n",
      "[I 2025-04-05 23:39:06,872] Trial 13 finished with value: 0.4565972089767456 and parameters: {'lstm_units': 256, 'dropout_rate': 0.3883664883193089, 'batch_size': 16}. Best is trial 12 with value: 0.4982638955116272.\n",
      "[I 2025-04-05 23:40:42,181] Trial 14 finished with value: 0.40625 and parameters: {'lstm_units': 223, 'dropout_rate': 0.4826527873392614, 'batch_size': 16}. Best is trial 12 with value: 0.4982638955116272.\n",
      "[I 2025-04-05 23:42:19,579] Trial 15 finished with value: 0.4392361044883728 and parameters: {'lstm_units': 256, 'dropout_rate': 0.356769256178954, 'batch_size': 32}. Best is trial 12 with value: 0.4982638955116272.\n",
      "[I 2025-04-05 23:44:14,811] Trial 16 finished with value: 0.4600694477558136 and parameters: {'lstm_units': 205, 'dropout_rate': 0.4173749133764258, 'batch_size': 16}. Best is trial 12 with value: 0.4982638955116272.\n",
      "[I 2025-04-05 23:46:17,503] Trial 17 finished with value: 0.4861111044883728 and parameters: {'lstm_units': 227, 'dropout_rate': 0.2923925364793127, 'batch_size': 16}. Best is trial 12 with value: 0.4982638955116272.\n",
      "[I 2025-04-05 23:47:13,036] Trial 18 finished with value: 0.4270833432674408 and parameters: {'lstm_units': 182, 'dropout_rate': 0.26740140754543895, 'batch_size': 64}. Best is trial 12 with value: 0.4982638955116272.\n",
      "[I 2025-04-05 23:48:41,550] Trial 19 finished with value: 0.4513888955116272 and parameters: {'lstm_units': 237, 'dropout_rate': 0.30793911938303714, 'batch_size': 32}. Best is trial 12 with value: 0.4982638955116272.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lstm_units': 253, 'dropout_rate': 0.3925523579584986, 'batch_size': 16}\n",
      "Epoch 1/50\n",
      "144/144 [==============================] - 11s 52ms/step - loss: 1.8939 - accuracy: 0.2643 - val_loss: 1.8923 - val_accuracy: 0.2674\n",
      "Epoch 2/50\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 1.8161 - accuracy: 0.3034 - val_loss: 1.7184 - val_accuracy: 0.3351\n",
      "Epoch 3/50\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 1.7362 - accuracy: 0.3333 - val_loss: 1.6430 - val_accuracy: 0.3472\n",
      "Epoch 4/50\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 1.6993 - accuracy: 0.3494 - val_loss: 1.6864 - val_accuracy: 0.3698\n",
      "Epoch 5/50\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 1.6801 - accuracy: 0.3498 - val_loss: 1.6270 - val_accuracy: 0.3837\n",
      "Epoch 6/50\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 1.6605 - accuracy: 0.3694 - val_loss: 1.6423 - val_accuracy: 0.3733\n",
      "Epoch 7/50\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 1.6336 - accuracy: 0.3793 - val_loss: 1.6412 - val_accuracy: 0.3594\n",
      "Epoch 8/50\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 1.6243 - accuracy: 0.3854 - val_loss: 1.5676 - val_accuracy: 0.3889\n",
      "Epoch 9/50\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 1.5990 - accuracy: 0.3802 - val_loss: 1.5405 - val_accuracy: 0.4080\n",
      "Epoch 10/50\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 1.5517 - accuracy: 0.4149 - val_loss: 1.5390 - val_accuracy: 0.4062\n",
      "Epoch 11/50\n",
      "144/144 [==============================] - 8s 52ms/step - loss: 1.5296 - accuracy: 0.4232 - val_loss: 1.5275 - val_accuracy: 0.4097\n",
      "Epoch 12/50\n",
      "144/144 [==============================] - 8s 57ms/step - loss: 1.5169 - accuracy: 0.4167 - val_loss: 1.4826 - val_accuracy: 0.4375\n",
      "Epoch 13/50\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 1.4849 - accuracy: 0.4488 - val_loss: 1.4328 - val_accuracy: 0.4583\n",
      "Epoch 14/50\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 1.4657 - accuracy: 0.4501 - val_loss: 1.4465 - val_accuracy: 0.4601\n",
      "Epoch 15/50\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 1.4411 - accuracy: 0.4479 - val_loss: 1.4648 - val_accuracy: 0.4497\n",
      "Epoch 16/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 1.4066 - accuracy: 0.4661 - val_loss: 1.3640 - val_accuracy: 0.4688\n",
      "Epoch 17/50\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 1.3708 - accuracy: 0.4818 - val_loss: 1.3435 - val_accuracy: 0.4774\n",
      "Epoch 18/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 1.3436 - accuracy: 0.4948 - val_loss: 1.3875 - val_accuracy: 0.4844\n",
      "Epoch 19/50\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 1.3059 - accuracy: 0.5169 - val_loss: 1.3484 - val_accuracy: 0.4809\n",
      "Epoch 20/50\n",
      "144/144 [==============================] - 7s 52ms/step - loss: 1.2921 - accuracy: 0.5122 - val_loss: 1.3271 - val_accuracy: 0.5035\n",
      "Epoch 21/50\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 1.2574 - accuracy: 0.5273 - val_loss: 1.3812 - val_accuracy: 0.4844\n",
      "Epoch 22/50\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 1.2445 - accuracy: 0.5217 - val_loss: 1.2658 - val_accuracy: 0.5052\n",
      "Epoch 23/50\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 1.1800 - accuracy: 0.5577 - val_loss: 1.2320 - val_accuracy: 0.5330\n",
      "Epoch 24/50\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 1.1403 - accuracy: 0.5751 - val_loss: 1.2054 - val_accuracy: 0.5694\n",
      "Epoch 25/50\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 1.0844 - accuracy: 0.5868 - val_loss: 1.1864 - val_accuracy: 0.5816\n",
      "Epoch 26/50\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 1.0669 - accuracy: 0.6094 - val_loss: 1.1619 - val_accuracy: 0.5660\n",
      "Epoch 27/50\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 1.0092 - accuracy: 0.6198 - val_loss: 1.1217 - val_accuracy: 0.6111\n",
      "Epoch 28/50\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 0.9378 - accuracy: 0.6523 - val_loss: 1.1766 - val_accuracy: 0.5660\n",
      "Epoch 29/50\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 0.8804 - accuracy: 0.6745 - val_loss: 1.0509 - val_accuracy: 0.6441\n",
      "Epoch 30/50\n",
      "144/144 [==============================] - 7s 52ms/step - loss: 0.8793 - accuracy: 0.6866 - val_loss: 1.0422 - val_accuracy: 0.5972\n",
      "Epoch 31/50\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 0.8107 - accuracy: 0.7049 - val_loss: 1.0247 - val_accuracy: 0.6528\n",
      "Epoch 32/50\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 0.7191 - accuracy: 0.7361 - val_loss: 1.0288 - val_accuracy: 0.6649\n",
      "Epoch 33/50\n",
      "144/144 [==============================] - 7s 52ms/step - loss: 0.7066 - accuracy: 0.7357 - val_loss: 1.0548 - val_accuracy: 0.6753\n",
      "Epoch 34/50\n",
      "144/144 [==============================] - 12s 84ms/step - loss: 0.6208 - accuracy: 0.7743 - val_loss: 1.0147 - val_accuracy: 0.6771\n",
      "Epoch 35/50\n",
      "144/144 [==============================] - 15s 106ms/step - loss: 0.5530 - accuracy: 0.8012 - val_loss: 0.9516 - val_accuracy: 0.6962\n",
      "Epoch 36/50\n",
      "144/144 [==============================] - 14s 95ms/step - loss: 0.5408 - accuracy: 0.8043 - val_loss: 0.8768 - val_accuracy: 0.7292\n",
      "Epoch 37/50\n",
      "144/144 [==============================] - 9s 60ms/step - loss: 0.5158 - accuracy: 0.8134 - val_loss: 0.8788 - val_accuracy: 0.7483\n",
      "Epoch 38/50\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.4374 - accuracy: 0.8507 - val_loss: 0.9873 - val_accuracy: 0.6892\n",
      "Epoch 39/50\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 0.4516 - accuracy: 0.8420 - val_loss: 0.8209 - val_accuracy: 0.7726\n",
      "Epoch 40/50\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 0.4187 - accuracy: 0.8494 - val_loss: 0.9271 - val_accuracy: 0.7448\n",
      "Epoch 41/50\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 0.3370 - accuracy: 0.8841 - val_loss: 0.8667 - val_accuracy: 0.7743\n",
      "Epoch 42/50\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 0.2921 - accuracy: 0.9019 - val_loss: 0.9141 - val_accuracy: 0.7431\n",
      "Epoch 43/50\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 0.3257 - accuracy: 0.8889 - val_loss: 0.7058 - val_accuracy: 0.8073\n",
      "Epoch 44/50\n",
      "144/144 [==============================] - 8s 56ms/step - loss: 0.2792 - accuracy: 0.9067 - val_loss: 0.9466 - val_accuracy: 0.7674\n",
      "Epoch 45/50\n",
      "144/144 [==============================] - 8s 55ms/step - loss: 0.2678 - accuracy: 0.9071 - val_loss: 0.8431 - val_accuracy: 0.8038\n",
      "Epoch 46/50\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 0.2144 - accuracy: 0.9310 - val_loss: 0.9271 - val_accuracy: 0.7986\n",
      "Epoch 47/50\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 0.2403 - accuracy: 0.9197 - val_loss: 0.7804 - val_accuracy: 0.8090\n",
      "Epoch 48/50\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 0.2780 - accuracy: 0.9076 - val_loss: 1.0002 - val_accuracy: 0.7795\n",
      "18/18 [==============================] - 1s 26ms/step - loss: 0.7058 - accuracy: 0.8073\n",
      "18/18 [==============================] - 1s 26ms/step\n",
      "Final Test Loss: 0.7058\n",
      "Final Test Accuracy: 80.73%\n",
      "Final Weighted F1 Score: 0.8086\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81        79\n",
      "           1       0.83      0.78      0.81        69\n",
      "           2       0.88      0.81      0.84        84\n",
      "           3       0.82      0.88      0.85        80\n",
      "           4       0.79      0.82      0.80        82\n",
      "           5       0.69      0.69      0.69        42\n",
      "           6       0.66      0.75      0.70        61\n",
      "           7       0.92      0.85      0.88        79\n",
      "\n",
      "    accuracy                           0.81       576\n",
      "   macro avg       0.80      0.80      0.80       576\n",
      "weighted avg       0.81      0.81      0.81       576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------- Preprocess Features ---------\n",
    "X = np.array(X)\n",
    "if X.ndim == 3:\n",
    "    X = X.squeeze(axis=1)\n",
    "\n",
    "y = LabelEncoder().fit_transform(y_clean)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_selected = feature_selection(X, y)\n",
    "\n",
    "# --------- Train-Test Split ---------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --------- Optuna Objective for LSTM ---------\n",
    "def objective(trial):\n",
    "    lstm_units = trial.suggest_int('lstm_units', 64, 256)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "\n",
    "    model = Sequential([\n",
    "        LSTM(units=lstm_units, input_shape=(X_train.shape[1], 1), return_sequences=False),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(len(np.unique(y)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train.reshape(-1, X_train.shape[1], 1), y_train,\n",
    "              validation_split=0.2, epochs=20, batch_size=batch_size,\n",
    "              callbacks=[early_stop], verbose=0)\n",
    "\n",
    "    _, accuracy = model.evaluate(X_test.reshape(-1, X_test.shape[1], 1), y_test, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "# --------- Run Optuna Study ---------\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# --------- Train Final Model ---------\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "final_model = Sequential([\n",
    "    LSTM(units=best_params['lstm_units'], input_shape=(X_train.shape[1], 1), return_sequences=False),\n",
    "    Dropout(best_params['dropout_rate']),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(best_params['dropout_rate']),\n",
    "    Dense(len(np.unique(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "final_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "final_model.fit(X_train.reshape(-1, X_train.shape[1], 1), y_train,\n",
    "                validation_data=(X_test.reshape(-1, X_test.shape[1], 1), y_test),\n",
    "                epochs=50, batch_size=best_params['batch_size'],\n",
    "                callbacks=[early_stop])\n",
    "\n",
    "# --------- Evaluation ---------\n",
    "eval_result = final_model.evaluate(X_test.reshape(-1, X_test.shape[1], 1), y_test)\n",
    "y_pred = np.argmax(final_model.predict(X_test.reshape(-1, X_test.shape[1], 1)), axis=1)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Final Test Loss: {eval_result[0]:.4f}\")\n",
    "print(f\"Final Test Accuracy: {eval_result[1]*100:.2f}%\")\n",
    "print(f\"Final Weighted F1 Score: {f1:.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
