{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "676ba85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 480/480 [01:07<00:00,  7.14it/s]\n",
      "[I 2025-04-06 12:37:20,400] A new study created in memory with name: no-name-5b1c1f78-5896-4ee9-ba0d-e453448088ea\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\samhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\samhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\samhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\samhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\samhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 12:37:37,422] Trial 0 finished with value: 0.6770833134651184 and parameters: {'filters1': 69, 'kernel1': 3, 'dropout': 0.2881315839456688, 'batch': 22}. Best is trial 0 with value: 0.6770833134651184.\n",
      "[I 2025-04-06 12:37:48,831] Trial 1 finished with value: 0.6979166865348816 and parameters: {'filters1': 43, 'kernel1': 4, 'dropout': 0.22322288299139398, 'batch': 38}. Best is trial 1 with value: 0.6979166865348816.\n",
      "[I 2025-04-06 12:38:00,818] Trial 2 finished with value: 0.6979166865348816 and parameters: {'filters1': 126, 'kernel1': 7, 'dropout': 0.3818525408167189, 'batch': 62}. Best is trial 1 with value: 0.6979166865348816.\n",
      "[I 2025-04-06 12:38:12,589] Trial 3 finished with value: 0.7291666865348816 and parameters: {'filters1': 126, 'kernel1': 6, 'dropout': 0.24222272653242335, 'batch': 60}. Best is trial 3 with value: 0.7291666865348816.\n",
      "[I 2025-04-06 12:38:23,180] Trial 4 finished with value: 0.7083333134651184 and parameters: {'filters1': 53, 'kernel1': 5, 'dropout': 0.455636784684389, 'batch': 44}. Best is trial 3 with value: 0.7291666865348816.\n",
      "[I 2025-04-06 12:38:40,398] Trial 5 finished with value: 0.7083333134651184 and parameters: {'filters1': 104, 'kernel1': 7, 'dropout': 0.4690612935365024, 'batch': 27}. Best is trial 3 with value: 0.7291666865348816.\n",
      "[I 2025-04-06 12:38:55,093] Trial 6 finished with value: 0.71875 and parameters: {'filters1': 63, 'kernel1': 7, 'dropout': 0.22348799657164448, 'batch': 51}. Best is trial 3 with value: 0.7291666865348816.\n",
      "[I 2025-04-06 12:39:10,503] Trial 7 finished with value: 0.6979166865348816 and parameters: {'filters1': 39, 'kernel1': 3, 'dropout': 0.45738895796795315, 'batch': 34}. Best is trial 3 with value: 0.7291666865348816.\n",
      "[I 2025-04-06 12:39:17,691] Trial 8 finished with value: 0.7083333134651184 and parameters: {'filters1': 113, 'kernel1': 6, 'dropout': 0.39843399585958295, 'batch': 55}. Best is trial 3 with value: 0.7291666865348816.\n",
      "[I 2025-04-06 12:39:30,476] Trial 9 finished with value: 0.6979166865348816 and parameters: {'filters1': 116, 'kernel1': 3, 'dropout': 0.48252802635880576, 'batch': 43}. Best is trial 3 with value: 0.7291666865348816.\n",
      "[I 2025-04-06 12:39:40,854] Trial 10 finished with value: 0.6875 and parameters: {'filters1': 92, 'kernel1': 5, 'dropout': 0.32608135475572864, 'batch': 64}. Best is trial 3 with value: 0.7291666865348816.\n",
      "[I 2025-04-06 12:39:51,957] Trial 11 finished with value: 0.7395833134651184 and parameters: {'filters1': 77, 'kernel1': 6, 'dropout': 0.20367438051040557, 'batch': 53}. Best is trial 11 with value: 0.7395833134651184.\n",
      "[I 2025-04-06 12:39:59,463] Trial 12 finished with value: 0.75 and parameters: {'filters1': 80, 'kernel1': 6, 'dropout': 0.20259823893610926, 'batch': 53}. Best is trial 12 with value: 0.75.\n",
      "[I 2025-04-06 12:40:09,884] Trial 13 finished with value: 0.7083333134651184 and parameters: {'filters1': 81, 'kernel1': 6, 'dropout': 0.20010244659720003, 'batch': 50}. Best is trial 12 with value: 0.75.\n",
      "[I 2025-04-06 12:40:20,637] Trial 14 finished with value: 0.71875 and parameters: {'filters1': 85, 'kernel1': 6, 'dropout': 0.27575650500384574, 'batch': 54}. Best is trial 12 with value: 0.75.\n",
      "[I 2025-04-06 12:40:31,197] Trial 15 finished with value: 0.71875 and parameters: {'filters1': 67, 'kernel1': 5, 'dropout': 0.28110442221046106, 'batch': 47}. Best is trial 12 with value: 0.75.\n",
      "[I 2025-04-06 12:40:39,722] Trial 16 finished with value: 0.7395833134651184 and parameters: {'filters1': 96, 'kernel1': 4, 'dropout': 0.32126419620339314, 'batch': 57}. Best is trial 12 with value: 0.75.\n",
      "[I 2025-04-06 12:40:52,371] Trial 17 finished with value: 0.75 and parameters: {'filters1': 55, 'kernel1': 6, 'dropout': 0.2542657232430976, 'batch': 34}. Best is trial 12 with value: 0.75.\n",
      "[I 2025-04-06 12:41:09,455] Trial 18 finished with value: 0.7291666865348816 and parameters: {'filters1': 32, 'kernel1': 5, 'dropout': 0.25704688663144637, 'batch': 31}. Best is trial 12 with value: 0.75.\n",
      "[I 2025-04-06 12:41:26,294] Trial 19 finished with value: 0.75 and parameters: {'filters1': 53, 'kernel1': 7, 'dropout': 0.31320938505257656, 'batch': 38}. Best is trial 12 with value: 0.75.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 229ms/step - loss: 1.7864 - accuracy: 0.3151 - val_loss: 1.4242 - val_accuracy: 0.4896\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 1.3945 - accuracy: 0.4740 - val_loss: 1.2258 - val_accuracy: 0.5729\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 67ms/step - loss: 1.2091 - accuracy: 0.5417 - val_loss: 1.0412 - val_accuracy: 0.6146\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 1.0585 - accuracy: 0.6120 - val_loss: 1.0064 - val_accuracy: 0.6354\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.9821 - accuracy: 0.6484 - val_loss: 0.9287 - val_accuracy: 0.6354\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.8906 - accuracy: 0.6641 - val_loss: 0.8790 - val_accuracy: 0.6979\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.8535 - accuracy: 0.6771 - val_loss: 0.8444 - val_accuracy: 0.6979\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.7558 - accuracy: 0.7292 - val_loss: 0.8061 - val_accuracy: 0.7188\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.7245 - accuracy: 0.7474 - val_loss: 0.8329 - val_accuracy: 0.6979\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.7069 - accuracy: 0.7448 - val_loss: 0.8054 - val_accuracy: 0.7083\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.6353 - accuracy: 0.7760 - val_loss: 0.7824 - val_accuracy: 0.6979\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.5888 - accuracy: 0.8021 - val_loss: 0.7988 - val_accuracy: 0.6875\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.5670 - accuracy: 0.8073 - val_loss: 0.7385 - val_accuracy: 0.7188\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 67ms/step - loss: 0.5187 - accuracy: 0.8203 - val_loss: 0.7483 - val_accuracy: 0.6875\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.5192 - accuracy: 0.8307 - val_loss: 0.7328 - val_accuracy: 0.6979\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.5146 - accuracy: 0.8281 - val_loss: 0.7163 - val_accuracy: 0.6979\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.4662 - accuracy: 0.8490 - val_loss: 0.7459 - val_accuracy: 0.6875\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.4022 - accuracy: 0.9062 - val_loss: 0.6875 - val_accuracy: 0.6979\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.4001 - accuracy: 0.8646 - val_loss: 0.7047 - val_accuracy: 0.7083\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.3635 - accuracy: 0.8984 - val_loss: 0.6906 - val_accuracy: 0.7292\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 67ms/step - loss: 0.3580 - accuracy: 0.8776 - val_loss: 0.6899 - val_accuracy: 0.7396\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.3273 - accuracy: 0.9036 - val_loss: 0.6962 - val_accuracy: 0.7188\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3016 - accuracy: 0.9271 - val_loss: 0.6857 - val_accuracy: 0.7396\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2762 - accuracy: 0.9193 - val_loss: 0.7041 - val_accuracy: 0.6875\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2725 - accuracy: 0.9219 - val_loss: 0.7104 - val_accuracy: 0.6875\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2462 - accuracy: 0.9401 - val_loss: 0.7064 - val_accuracy: 0.7083\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.2487 - accuracy: 0.9271 - val_loss: 0.6964 - val_accuracy: 0.7396\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.2298 - accuracy: 0.9401 - val_loss: 0.6942 - val_accuracy: 0.7083\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.80      0.67         5\n",
      "           1       1.00      0.58      0.74        12\n",
      "           2       0.55      0.50      0.52        12\n",
      "           3       0.50      0.50      0.50        10\n",
      "           4       0.86      0.94      0.90        32\n",
      "           5       0.77      0.71      0.74        14\n",
      "           6       0.46      0.55      0.50        11\n",
      "\n",
      "    accuracy                           0.71        96\n",
      "   macro avg       0.67      0.65      0.65        96\n",
      "weighted avg       0.73      0.71      0.71        96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "import optuna\n",
    "\n",
    "# ------------------- Load SAVEE -------------------\n",
    "def load_savee_audio(dataset_path):\n",
    "    audio_files = []\n",
    "    labels = []\n",
    "\n",
    "    label_map = {\n",
    "        'a': 'angry', 'd': 'disgust', 'f': 'fear', 'h': 'happy',\n",
    "        'n': 'neutral', 'sa': 'sad', 'su': 'surprise'\n",
    "    }\n",
    "\n",
    "    for file in os.listdir(dataset_path):\n",
    "        if file.endswith(\".wav\"):\n",
    "            parts = file.split('_')\n",
    "            emotion_code = parts[1][:2] if parts[1][:2] in label_map else parts[1][0]\n",
    "            if emotion_code in label_map:\n",
    "                emotion = label_map[emotion_code]\n",
    "                audio_files.append(os.path.join(dataset_path, file))\n",
    "                labels.append(emotion)\n",
    "\n",
    "    return audio_files, labels\n",
    "\n",
    "# Feature extraction: MFCC + ZCR + RMS\n",
    "def extract_custom_features(file_path, sr=22050):\n",
    "    y, sr = librosa.load(file_path, sr=sr)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    features = np.concatenate((mfcc, zcr, rms), axis=0)\n",
    "    return np.mean(features.T, axis=0)\n",
    "\n",
    "dataset_path = \"C:/Users/samhi/OneDrive/문서/College/s6/Speech Processing/Endsem/archive/ALL\"\n",
    "\n",
    "audio_files, labels = load_savee_audio(dataset_path)\n",
    "\n",
    "X, y_clean = [], []\n",
    "for file, label in tqdm(zip(audio_files, labels), total=len(audio_files)):\n",
    "    try:\n",
    "        features = extract_custom_features(file)\n",
    "        X.append(features)\n",
    "        y_clean.append(label)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "X = np.array(X)\n",
    "y = LabelEncoder().fit_transform(y_clean)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ------------------- DCNN with Optuna -------------------\n",
    "def objective(trial):\n",
    "    model = Sequential([\n",
    "        Conv1D(trial.suggest_int('filters1', 32, 128), kernel_size=trial.suggest_int('kernel1', 3, 7),\n",
    "               activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(trial.suggest_float('dropout', 0.2, 0.5)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(trial.suggest_float('dropout', 0.2, 0.5)),\n",
    "        Dense(len(set(y)), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train.reshape(-1, X_train.shape[1], 1), y_train, epochs=20, batch_size=trial.suggest_int('batch', 16, 64), verbose=0,\n",
    "              validation_data=(X_test.reshape(-1, X_test.shape[1], 1), y_test), callbacks=[EarlyStopping(patience=3)])\n",
    "    _, acc = model.evaluate(X_test.reshape(-1, X_test.shape[1], 1), y_test, verbose=0)\n",
    "    return acc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "params = study.best_params\n",
    "model = Sequential([\n",
    "    Conv1D(params['filters1'], kernel_size=params['kernel1'], activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(params['dropout']),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(params['dropout']),\n",
    "    Dense(len(set(y)), activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train.reshape(-1, X_train.shape[1], 1), y_train, epochs=50, batch_size=params['batch'], validation_data=(X_test.reshape(-1, X_test.shape[1], 1), y_test), callbacks=[EarlyStopping(patience=5)])\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(X_test.reshape(-1, X_test.shape[1], 1))\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
