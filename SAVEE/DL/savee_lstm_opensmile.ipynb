{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c527f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 480 audio files from SAVEE.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 480/480 [01:39<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1 ---\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "Fold Accuracy: 0.4167, Macro F1: 0.2996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.58      0.37        12\n",
      "           1       0.33      0.17      0.22        12\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.38      0.25      0.30        12\n",
      "           4       0.51      0.83      0.63        24\n",
      "           5       0.00      0.00      0.00        12\n",
      "           6       0.50      0.67      0.57        12\n",
      "\n",
      "    accuracy                           0.42        96\n",
      "   macro avg       0.28      0.36      0.30        96\n",
      "weighted avg       0.31      0.42      0.34        96\n",
      "\n",
      "\n",
      "--- Fold 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\samhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\samhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "Fold Accuracy: 0.3958, Macro F1: 0.3231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.50      0.30        12\n",
      "           1       0.20      0.17      0.18        12\n",
      "           2       0.50      0.25      0.33        12\n",
      "           3       0.20      0.08      0.12        12\n",
      "           4       0.65      0.83      0.73        24\n",
      "           5       0.43      0.25      0.32        12\n",
      "           6       0.33      0.25      0.29        12\n",
      "\n",
      "    accuracy                           0.40        96\n",
      "   macro avg       0.36      0.33      0.32        96\n",
      "weighted avg       0.40      0.40      0.37        96\n",
      "\n",
      "\n",
      "--- Fold 3 ---\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "Fold Accuracy: 0.3750, Macro F1: 0.2627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.42      0.30        12\n",
      "           1       0.00      0.00      0.00        12\n",
      "           2       0.20      0.25      0.22        12\n",
      "           3       0.25      0.25      0.25        12\n",
      "           4       0.56      0.92      0.70        24\n",
      "           5       0.33      0.17      0.22        12\n",
      "           6       0.50      0.08      0.14        12\n",
      "\n",
      "    accuracy                           0.38        96\n",
      "   macro avg       0.30      0.30      0.26        96\n",
      "weighted avg       0.33      0.38      0.32        96\n",
      "\n",
      "\n",
      "--- Fold 4 ---\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000025ED2531440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "Fold Accuracy: 0.4167, Macro F1: 0.3205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.58      0.32        12\n",
      "           1       0.00      0.00      0.00        12\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.30      0.25      0.27        12\n",
      "           4       0.62      0.75      0.68        24\n",
      "           5       0.50      0.58      0.54        12\n",
      "           6       0.45      0.42      0.43        12\n",
      "\n",
      "    accuracy                           0.42        96\n",
      "   macro avg       0.30      0.37      0.32        96\n",
      "weighted avg       0.34      0.42      0.37        96\n",
      "\n",
      "\n",
      "--- Fold 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\samhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\samhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000025EDA7BF740> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "Fold Accuracy: 0.4375, Macro F1: 0.4134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.42      0.38        12\n",
      "           1       0.21      0.33      0.26        12\n",
      "           2       0.75      0.25      0.38        12\n",
      "           3       0.50      0.33      0.40        12\n",
      "           4       0.60      0.62      0.61        24\n",
      "           5       0.40      0.33      0.36        12\n",
      "           6       0.44      0.58      0.50        12\n",
      "\n",
      "    accuracy                           0.44        96\n",
      "   macro avg       0.47      0.41      0.41        96\n",
      "weighted avg       0.48      0.44      0.44        96\n",
      "\n",
      "\n",
      "=== Cross-Validation Summary ===\n",
      "Mean Accuracy: 40.83%\n",
      "Mean Macro F1 Score: 0.3238\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import opensmile\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# ------------------- Load SAVEE -------------------\n",
    "def load_savee_audio(dataset_path):\n",
    "    audio_files = []\n",
    "    labels = []\n",
    "    label_map = {\n",
    "        'a': 'angry', 'd': 'disgust', 'f': 'fear', 'h': 'happy',\n",
    "        'n': 'neutral', 'sa': 'sad', 'su': 'surprise'\n",
    "    }\n",
    "\n",
    "    for file in os.listdir(dataset_path):\n",
    "        if file.endswith(\".wav\"):\n",
    "            parts = file.split('_')\n",
    "            emotion_code = parts[1][:2] if parts[1][:2] in label_map else parts[1][0]\n",
    "            if emotion_code in label_map:\n",
    "                emotion = label_map[emotion_code]\n",
    "                audio_files.append(os.path.join(dataset_path, file))\n",
    "                labels.append(emotion)\n",
    "\n",
    "    print(f\"Loaded {len(audio_files)} audio files from SAVEE.\")\n",
    "    return audio_files, labels\n",
    "\n",
    "# OpenSMILE Feature Extraction\n",
    "def extract_opensmile_features(file_path):\n",
    "    smile = opensmile.Smile(\n",
    "        feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "        feature_level=opensmile.FeatureLevel.Functionals\n",
    "    )\n",
    "    features = smile.process_file(file_path)\n",
    "    return features.values.flatten()\n",
    "\n",
    "# ------------------- Load & Extract Features -------------------\n",
    "dataset_path = \"C:/Users/samhi/OneDrive/문서/College/s6/Speech Processing/Endsem/archive/ALL\"\n",
    "audio_files, labels = load_savee_audio(dataset_path)\n",
    "\n",
    "X, y_clean = [], []\n",
    "for file, label in tqdm(zip(audio_files, labels), total=len(audio_files)):\n",
    "    try:\n",
    "        features = extract_opensmile_features(file)\n",
    "        if features.size > 0:\n",
    "            X.append(features)\n",
    "            y_clean.append(label)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "X = np.array(X)\n",
    "y = LabelEncoder().fit_transform(y_clean)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# ------------------- Cross-validation Setup -------------------\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y), 1):\n",
    "    print(f\"\\n--- Fold {fold} ---\")\n",
    "    \n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Reshape for LSTM: (samples, timesteps, features)\n",
    "    X_train_lstm = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "    X_test_lstm = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=(1, X.shape[1]), return_sequences=False),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(len(np.unique(y)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    model.fit(X_train_lstm, y_train, epochs=40, batch_size=16,\n",
    "              validation_split=0.2, callbacks=[es], verbose=0)\n",
    "\n",
    "    y_pred = np.argmax(model.predict(X_test_lstm), axis=1)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(f\"Fold Accuracy: {acc:.4f}, Macro F1: {f1:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    accuracies.append(acc)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# ------------------- Final Summary -------------------\n",
    "print(\"\\n=== Cross-Validation Summary ===\")\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies)*100:.2f}%\")\n",
    "print(f\"Mean Macro F1 Score: {np.mean(f1_scores):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
