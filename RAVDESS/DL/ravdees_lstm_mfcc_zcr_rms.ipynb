{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d54d567a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\samhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-05 23:40:56,810] A new study created in memory with name: no-name-7380421a-b2a1-4b20-8542-a65de40f5a7b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features from 2880 files.\n",
      "Skipped 0 files.\n",
      "WARNING:tensorflow:From C:\\Users\\samhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:148: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\samhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\samhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\samhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-05 23:42:23,156] Trial 0 finished with value: 0.4270833432674408 and parameters: {'lstm_units': 254, 'dropout_rate': 0.45495634370246135, 'batch_size': 32}. Best is trial 0 with value: 0.4270833432674408.\n",
      "[I 2025-04-05 23:43:09,977] Trial 1 finished with value: 0.4357638955116272 and parameters: {'lstm_units': 156, 'dropout_rate': 0.20971218622363244, 'batch_size': 64}. Best is trial 1 with value: 0.4357638955116272.\n",
      "[I 2025-04-05 23:43:53,742] Trial 2 finished with value: 0.3958333432674408 and parameters: {'lstm_units': 116, 'dropout_rate': 0.49489214744624166, 'batch_size': 64}. Best is trial 1 with value: 0.4357638955116272.\n",
      "[I 2025-04-05 23:45:44,643] Trial 3 finished with value: 0.4947916567325592 and parameters: {'lstm_units': 219, 'dropout_rate': 0.3545965221023448, 'batch_size': 16}. Best is trial 3 with value: 0.4947916567325592.\n",
      "[I 2025-04-05 23:47:09,111] Trial 4 finished with value: 0.5208333134651184 and parameters: {'lstm_units': 201, 'dropout_rate': 0.2336306603127598, 'batch_size': 16}. Best is trial 4 with value: 0.5208333134651184.\n",
      "[I 2025-04-05 23:48:40,980] Trial 5 finished with value: 0.4288194477558136 and parameters: {'lstm_units': 221, 'dropout_rate': 0.46976965431599027, 'batch_size': 16}. Best is trial 4 with value: 0.5208333134651184.\n",
      "[I 2025-04-05 23:49:19,407] Trial 6 finished with value: 0.4288194477558136 and parameters: {'lstm_units': 154, 'dropout_rate': 0.3230861767573616, 'batch_size': 64}. Best is trial 4 with value: 0.5208333134651184.\n",
      "[I 2025-04-05 23:49:46,043] Trial 7 finished with value: 0.3975694477558136 and parameters: {'lstm_units': 74, 'dropout_rate': 0.4921439948547419, 'batch_size': 64}. Best is trial 4 with value: 0.5208333134651184.\n",
      "[I 2025-04-05 23:50:52,500] Trial 8 finished with value: 0.4270833432674408 and parameters: {'lstm_units': 253, 'dropout_rate': 0.4149391498590579, 'batch_size': 64}. Best is trial 4 with value: 0.5208333134651184.\n",
      "[I 2025-04-05 23:51:25,064] Trial 9 finished with value: 0.4409722089767456 and parameters: {'lstm_units': 97, 'dropout_rate': 0.3177210316369562, 'batch_size': 64}. Best is trial 4 with value: 0.5208333134651184.\n",
      "[I 2025-04-05 23:53:14,660] Trial 10 finished with value: 0.5121527910232544 and parameters: {'lstm_units': 200, 'dropout_rate': 0.22041377305030327, 'batch_size': 16}. Best is trial 4 with value: 0.5208333134651184.\n",
      "[I 2025-04-05 23:54:50,599] Trial 11 finished with value: 0.5486111044883728 and parameters: {'lstm_units': 194, 'dropout_rate': 0.2065420143531594, 'batch_size': 16}. Best is trial 11 with value: 0.5486111044883728.\n",
      "[I 2025-04-05 23:56:09,884] Trial 12 finished with value: 0.4930555522441864 and parameters: {'lstm_units': 196, 'dropout_rate': 0.26157427726710597, 'batch_size': 16}. Best is trial 11 with value: 0.5486111044883728.\n",
      "[I 2025-04-05 23:57:31,090] Trial 13 finished with value: 0.5104166865348816 and parameters: {'lstm_units': 173, 'dropout_rate': 0.25280157726870994, 'batch_size': 16}. Best is trial 11 with value: 0.5486111044883728.\n",
      "[I 2025-04-05 23:58:15,512] Trial 14 finished with value: 0.40625 and parameters: {'lstm_units': 176, 'dropout_rate': 0.2714945253549996, 'batch_size': 32}. Best is trial 11 with value: 0.5486111044883728.\n",
      "[I 2025-04-05 23:59:06,254] Trial 15 finished with value: 0.5052083134651184 and parameters: {'lstm_units': 137, 'dropout_rate': 0.2003852924191629, 'batch_size': 16}. Best is trial 11 with value: 0.5486111044883728.\n",
      "[I 2025-04-06 00:00:17,900] Trial 16 finished with value: 0.4947916567325592 and parameters: {'lstm_units': 217, 'dropout_rate': 0.291067824087729, 'batch_size': 16}. Best is trial 11 with value: 0.5486111044883728.\n",
      "[I 2025-04-06 00:01:22,006] Trial 17 finished with value: 0.4756944477558136 and parameters: {'lstm_units': 195, 'dropout_rate': 0.3630114668219888, 'batch_size': 16}. Best is trial 11 with value: 0.5486111044883728.\n",
      "[I 2025-04-06 00:02:21,254] Trial 18 finished with value: 0.4878472089767456 and parameters: {'lstm_units': 235, 'dropout_rate': 0.2346385551778892, 'batch_size': 32}. Best is trial 11 with value: 0.5486111044883728.\n",
      "[I 2025-04-06 00:03:07,837] Trial 19 finished with value: 0.4618055522441864 and parameters: {'lstm_units': 132, 'dropout_rate': 0.39081069296061033, 'batch_size': 16}. Best is trial 11 with value: 0.5486111044883728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lstm_units': 194, 'dropout_rate': 0.2065420143531594, 'batch_size': 16}\n",
      "Epoch 1/50\n",
      "144/144 [==============================] - 6s 30ms/step - loss: 1.9509 - accuracy: 0.2352 - val_loss: 1.8350 - val_accuracy: 0.3229\n",
      "Epoch 2/50\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 1.8142 - accuracy: 0.3125 - val_loss: 1.7565 - val_accuracy: 0.3438\n",
      "Epoch 3/50\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.7451 - accuracy: 0.3372 - val_loss: 1.6703 - val_accuracy: 0.3750\n",
      "Epoch 4/50\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 1.6768 - accuracy: 0.3628 - val_loss: 1.6820 - val_accuracy: 0.3663\n",
      "Epoch 5/50\n",
      "144/144 [==============================] - 8s 58ms/step - loss: 1.6426 - accuracy: 0.3707 - val_loss: 1.5947 - val_accuracy: 0.4028\n",
      "Epoch 6/50\n",
      "144/144 [==============================] - 74s 520ms/step - loss: 1.6057 - accuracy: 0.3845 - val_loss: 1.5916 - val_accuracy: 0.3819\n",
      "Epoch 7/50\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 1.5748 - accuracy: 0.3963 - val_loss: 1.5772 - val_accuracy: 0.3941\n",
      "Epoch 8/50\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 1.5525 - accuracy: 0.4045 - val_loss: 1.5261 - val_accuracy: 0.4583\n",
      "Epoch 9/50\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 1.5233 - accuracy: 0.4128 - val_loss: 1.5326 - val_accuracy: 0.4410\n",
      "Epoch 10/50\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 1.5076 - accuracy: 0.4201 - val_loss: 1.4659 - val_accuracy: 0.4531\n",
      "Epoch 11/50\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 1.4696 - accuracy: 0.4371 - val_loss: 1.4505 - val_accuracy: 0.4497\n",
      "Epoch 12/50\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 1.4246 - accuracy: 0.4518 - val_loss: 1.4245 - val_accuracy: 0.4514\n",
      "Epoch 13/50\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 1.3844 - accuracy: 0.4701 - val_loss: 1.4241 - val_accuracy: 0.4774\n",
      "Epoch 14/50\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 1.3485 - accuracy: 0.4909 - val_loss: 1.3498 - val_accuracy: 0.5295\n",
      "Epoch 15/50\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 1.3338 - accuracy: 0.4939 - val_loss: 1.3286 - val_accuracy: 0.5451\n",
      "Epoch 16/50\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 1.2994 - accuracy: 0.5030 - val_loss: 1.2663 - val_accuracy: 0.5278\n",
      "Epoch 17/50\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 1.2328 - accuracy: 0.5321 - val_loss: 1.2649 - val_accuracy: 0.5347\n",
      "Epoch 18/50\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 1.1866 - accuracy: 0.5443 - val_loss: 1.2454 - val_accuracy: 0.5538\n",
      "Epoch 19/50\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 1.1469 - accuracy: 0.5742 - val_loss: 1.1448 - val_accuracy: 0.5972\n",
      "Epoch 20/50\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 1.0877 - accuracy: 0.6007 - val_loss: 1.2029 - val_accuracy: 0.5764\n",
      "Epoch 21/50\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 1.0546 - accuracy: 0.6085 - val_loss: 1.1322 - val_accuracy: 0.6024\n",
      "Epoch 22/50\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 0.9741 - accuracy: 0.6298 - val_loss: 1.1757 - val_accuracy: 0.5781\n",
      "Epoch 23/50\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 0.9339 - accuracy: 0.6580 - val_loss: 1.1668 - val_accuracy: 0.5851\n",
      "Epoch 24/50\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 0.8865 - accuracy: 0.6753 - val_loss: 1.1200 - val_accuracy: 0.6094\n",
      "Epoch 25/50\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 0.8589 - accuracy: 0.6871 - val_loss: 0.9652 - val_accuracy: 0.6858\n",
      "Epoch 26/50\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 0.8005 - accuracy: 0.7114 - val_loss: 0.9838 - val_accuracy: 0.6597\n",
      "Epoch 27/50\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 0.7657 - accuracy: 0.7313 - val_loss: 0.8854 - val_accuracy: 0.7066\n",
      "Epoch 28/50\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 0.6675 - accuracy: 0.7708 - val_loss: 0.8674 - val_accuracy: 0.6997\n",
      "Epoch 29/50\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 0.6452 - accuracy: 0.7747 - val_loss: 0.8904 - val_accuracy: 0.6858\n",
      "Epoch 30/50\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.6150 - accuracy: 0.7847 - val_loss: 0.8328 - val_accuracy: 0.7292\n",
      "Epoch 31/50\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 0.5205 - accuracy: 0.8199 - val_loss: 0.8473 - val_accuracy: 0.7222\n",
      "Epoch 32/50\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 0.5258 - accuracy: 0.8121 - val_loss: 0.8040 - val_accuracy: 0.7344\n",
      "Epoch 33/50\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 0.4476 - accuracy: 0.8429 - val_loss: 0.7777 - val_accuracy: 0.7517\n",
      "Epoch 34/50\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 0.3914 - accuracy: 0.8685 - val_loss: 0.7593 - val_accuracy: 0.7622\n",
      "Epoch 35/50\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 0.3854 - accuracy: 0.8694 - val_loss: 0.7428 - val_accuracy: 0.7969\n",
      "Epoch 36/50\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 0.3844 - accuracy: 0.8750 - val_loss: 0.6575 - val_accuracy: 0.8021\n",
      "Epoch 37/50\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 0.3469 - accuracy: 0.8802 - val_loss: 0.6413 - val_accuracy: 0.8038\n",
      "Epoch 38/50\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 0.3090 - accuracy: 0.8911 - val_loss: 0.6990 - val_accuracy: 0.8194\n",
      "Epoch 39/50\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 0.2681 - accuracy: 0.9071 - val_loss: 0.5964 - val_accuracy: 0.8576\n",
      "Epoch 40/50\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 0.2118 - accuracy: 0.9280 - val_loss: 0.7200 - val_accuracy: 0.8316\n",
      "Epoch 41/50\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 0.2199 - accuracy: 0.9280 - val_loss: 0.6370 - val_accuracy: 0.8316\n",
      "Epoch 42/50\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 0.2010 - accuracy: 0.9362 - val_loss: 0.6400 - val_accuracy: 0.8333\n",
      "Epoch 43/50\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 0.2192 - accuracy: 0.9266 - val_loss: 0.6781 - val_accuracy: 0.8142\n",
      "Epoch 44/50\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 0.2659 - accuracy: 0.9149 - val_loss: 0.7244 - val_accuracy: 0.8576\n",
      "18/18 [==============================] - 1s 16ms/step - loss: 0.5964 - accuracy: 0.8576\n",
      "18/18 [==============================] - 1s 17ms/step\n",
      "Final Test Loss: 0.5964\n",
      "Final Test Accuracy: 85.76%\n",
      "Final Weighted F1 Score: 0.8570\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90        79\n",
      "           1       0.84      0.97      0.90        69\n",
      "           2       0.85      0.86      0.85        84\n",
      "           3       0.86      0.79      0.82        80\n",
      "           4       0.79      0.85      0.82        82\n",
      "           5       0.86      0.71      0.78        42\n",
      "           6       0.87      0.87      0.87        61\n",
      "           7       0.87      0.91      0.89        79\n",
      "\n",
      "    accuracy                           0.86       576\n",
      "   macro avg       0.86      0.85      0.85       576\n",
      "weighted avg       0.86      0.86      0.86       576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import optuna\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# --------- Load Audio Files ---------\n",
    "def load_audio_files_ravdess(dataset_path):\n",
    "    audio_files = []\n",
    "    labels = []\n",
    "    for root, _, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                emotion_code = int(file.split(\"-\")[2])\n",
    "                audio_files.append(os.path.join(root, file))\n",
    "                labels.append(emotion_code)\n",
    "    return audio_files, labels\n",
    "\n",
    "# --------- Map Emotion Labels ---------\n",
    "def map_emotions_ravdess(labels):\n",
    "    emotion_dict = {\n",
    "        1: 'neutral', 2: 'calm', 3: 'happy', 4: 'sad',\n",
    "        5: 'angry', 6: 'fearful', 7: 'disgust', 8: 'surprised'\n",
    "    }\n",
    "    return [emotion_dict[label] for label in labels]\n",
    "\n",
    "# --------- Extract MFCC + ZCR + RMS ---------\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "\n",
    "    # Average pooling\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "    zcr_mean = np.mean(zcr)\n",
    "    rms_mean = np.mean(rms)\n",
    "\n",
    "    return np.concatenate((mfccs_mean, [zcr_mean, rms_mean]))\n",
    "\n",
    "# --------- Load Dataset and Extract Features ---------\n",
    "dataset_path = \"C:/Users/samhi/OneDrive/문서/College/s6/Speech Processing/Endsem/Final codes/ravdees\"\n",
    "\n",
    "audio_files, labels = load_audio_files_ravdess(dataset_path)\n",
    "labels_mapped = map_emotions_ravdess(labels)\n",
    "\n",
    "X = []\n",
    "y_clean = []\n",
    "failed = []\n",
    "\n",
    "for file, label in zip(audio_files, labels_mapped):\n",
    "    try:\n",
    "        features = extract_features(file)\n",
    "        X.append(features)\n",
    "        y_clean.append(label)\n",
    "    except Exception as e:\n",
    "        failed.append((file, str(e)))\n",
    "\n",
    "print(f\"Extracted features from {len(X)} files.\")\n",
    "print(f\"Skipped {len(failed)} files.\")\n",
    "\n",
    "# --------- Preprocess ---------\n",
    "X = np.array(X)\n",
    "y = LabelEncoder().fit_transform(y_clean)\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # Reshape for LSTM\n",
    "\n",
    "# --------- Split ---------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --------- Optuna Objective ---------\n",
    "def objective(trial):\n",
    "    lstm_units = trial.suggest_int(\"lstm_units\", 64, 256)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.2, 0.5)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "\n",
    "    model = Sequential([\n",
    "        LSTM(units=lstm_units, input_shape=(X_train.shape[1], 1), return_sequences=False),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(len(np.unique(y)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              validation_split=0.2, epochs=20, batch_size=batch_size,\n",
    "              callbacks=[early_stop], verbose=0)\n",
    "\n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "# --------- Run Optuna ---------\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# --------- Final Model ---------\n",
    "final_model = Sequential([\n",
    "    LSTM(units=best_params['lstm_units'], input_shape=(X_train.shape[1], 1), return_sequences=False),\n",
    "    Dropout(best_params['dropout_rate']),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(best_params['dropout_rate']),\n",
    "    Dense(len(np.unique(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "final_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "final_model.fit(X_train, y_train,\n",
    "                validation_data=(X_test, y_test),\n",
    "                epochs=50, batch_size=best_params['batch_size'],\n",
    "                callbacks=[early_stop])\n",
    "\n",
    "# --------- Evaluation ---------\n",
    "eval_result = final_model.evaluate(X_test, y_test)\n",
    "y_pred = np.argmax(final_model.predict(X_test), axis=1)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Final Test Loss: {eval_result[0]:.4f}\")\n",
    "print(f\"Final Test Accuracy: {eval_result[1]*100:.2f}%\")\n",
    "print(f\"Final Weighted F1 Score: {f1:.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f5bd69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
