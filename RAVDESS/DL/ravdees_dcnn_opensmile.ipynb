{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2880 audio files in total.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2880/2880 [16:01<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features from 2880 files.\n",
      "Skipped 0 files due to errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:09:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-04-05 23:15:13,798] A new study created in memory with name: no-name-7e89f760-ef63-4560-b43a-9529ce6f5bb5\n",
      "[I 2025-04-05 23:15:28,864] Trial 0 finished with value: 0.8368055820465088 and parameters: {'filters_1': 61, 'filters_2': 212, 'kernel_size': 7, 'dropout_rate': 0.2862364872139174, 'batch_size': 32}. Best is trial 0 with value: 0.8368055820465088.\n",
      "[I 2025-04-05 23:15:50,255] Trial 1 finished with value: 0.6527777910232544 and parameters: {'filters_1': 43, 'filters_2': 156, 'kernel_size': 5, 'dropout_rate': 0.48214337229168935, 'batch_size': 21}. Best is trial 0 with value: 0.8368055820465088.\n",
      "[I 2025-04-05 23:16:04,736] Trial 2 finished with value: 0.625 and parameters: {'filters_1': 57, 'filters_2': 147, 'kernel_size': 4, 'dropout_rate': 0.4711899526705762, 'batch_size': 53}. Best is trial 0 with value: 0.8368055820465088.\n",
      "[I 2025-04-05 23:16:29,194] Trial 3 finished with value: 0.7378472089767456 and parameters: {'filters_1': 82, 'filters_2': 142, 'kernel_size': 6, 'dropout_rate': 0.3831592706352739, 'batch_size': 34}. Best is trial 0 with value: 0.8368055820465088.\n",
      "[I 2025-04-05 23:16:51,486] Trial 4 finished with value: 0.7222222089767456 and parameters: {'filters_1': 76, 'filters_2': 224, 'kernel_size': 7, 'dropout_rate': 0.44780613136706704, 'batch_size': 61}. Best is trial 0 with value: 0.8368055820465088.\n",
      "[I 2025-04-05 23:17:16,629] Trial 5 finished with value: 0.7725694179534912 and parameters: {'filters_1': 110, 'filters_2': 68, 'kernel_size': 3, 'dropout_rate': 0.30777477642579343, 'batch_size': 33}. Best is trial 0 with value: 0.8368055820465088.\n",
      "[I 2025-04-05 23:17:47,984] Trial 6 finished with value: 0.71875 and parameters: {'filters_1': 63, 'filters_2': 102, 'kernel_size': 3, 'dropout_rate': 0.3911127465187535, 'batch_size': 17}. Best is trial 0 with value: 0.8368055820465088.\n",
      "[I 2025-04-05 23:18:07,969] Trial 7 finished with value: 0.7395833134651184 and parameters: {'filters_1': 79, 'filters_2': 197, 'kernel_size': 6, 'dropout_rate': 0.3767128264513626, 'batch_size': 48}. Best is trial 0 with value: 0.8368055820465088.\n",
      "[I 2025-04-05 23:18:26,573] Trial 8 finished with value: 0.6545138955116272 and parameters: {'filters_1': 67, 'filters_2': 107, 'kernel_size': 3, 'dropout_rate': 0.45141449781974075, 'batch_size': 44}. Best is trial 0 with value: 0.8368055820465088.\n",
      "[I 2025-04-05 23:18:46,748] Trial 9 finished with value: 0.8211805820465088 and parameters: {'filters_1': 116, 'filters_2': 97, 'kernel_size': 7, 'dropout_rate': 0.20874356955022966, 'batch_size': 57}. Best is trial 0 with value: 0.8368055820465088.\n",
      "[I 2025-04-05 23:19:12,453] Trial 10 finished with value: 0.8402777910232544 and parameters: {'filters_1': 35, 'filters_2': 254, 'kernel_size': 6, 'dropout_rate': 0.2767985221359846, 'batch_size': 28}. Best is trial 10 with value: 0.8402777910232544.\n",
      "[I 2025-04-05 23:19:37,695] Trial 11 finished with value: 0.8229166865348816 and parameters: {'filters_1': 33, 'filters_2': 254, 'kernel_size': 6, 'dropout_rate': 0.27067029331859804, 'batch_size': 28}. Best is trial 10 with value: 0.8402777910232544.\n",
      "[I 2025-04-05 23:20:06,742] Trial 12 finished with value: 0.8645833134651184 and parameters: {'filters_1': 48, 'filters_2': 251, 'kernel_size': 7, 'dropout_rate': 0.2662244862335018, 'batch_size': 26}. Best is trial 12 with value: 0.8645833134651184.\n",
      "[I 2025-04-05 23:20:32,905] Trial 13 finished with value: 0.8767361044883728 and parameters: {'filters_1': 32, 'filters_2': 256, 'kernel_size': 5, 'dropout_rate': 0.23146611496841, 'batch_size': 25}. Best is trial 13 with value: 0.8767361044883728.\n",
      "[I 2025-04-05 23:20:59,801] Trial 14 finished with value: 0.8802083134651184 and parameters: {'filters_1': 48, 'filters_2': 183, 'kernel_size': 5, 'dropout_rate': 0.20842805706560544, 'batch_size': 23}. Best is trial 14 with value: 0.8802083134651184.\n",
      "[I 2025-04-05 23:21:19,886] Trial 15 finished with value: 0.859375 and parameters: {'filters_1': 47, 'filters_2': 184, 'kernel_size': 5, 'dropout_rate': 0.2167127296912972, 'batch_size': 40}. Best is trial 14 with value: 0.8802083134651184.\n",
      "[I 2025-04-05 23:21:56,617] Trial 16 finished with value: 0.8871527910232544 and parameters: {'filters_1': 98, 'filters_2': 176, 'kernel_size': 4, 'dropout_rate': 0.23523625332403125, 'batch_size': 16}. Best is trial 16 with value: 0.8871527910232544.\n",
      "[I 2025-04-05 23:22:28,991] Trial 17 finished with value: 0.8854166865348816 and parameters: {'filters_1': 98, 'filters_2': 179, 'kernel_size': 4, 'dropout_rate': 0.3251452862756661, 'batch_size': 16}. Best is trial 16 with value: 0.8871527910232544.\n",
      "[I 2025-04-05 23:22:58,367] Trial 18 finished with value: 0.8576388955116272 and parameters: {'filters_1': 97, 'filters_2': 173, 'kernel_size': 4, 'dropout_rate': 0.33043597132064984, 'batch_size': 17}. Best is trial 16 with value: 0.8871527910232544.\n",
      "[I 2025-04-05 23:23:25,759] Trial 19 finished with value: 0.8315972089767456 and parameters: {'filters_1': 98, 'filters_2': 122, 'kernel_size': 4, 'dropout_rate': 0.34516797598502946, 'batch_size': 16}. Best is trial 16 with value: 0.8871527910232544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'filters_1': 98, 'filters_2': 176, 'kernel_size': 4, 'dropout_rate': 0.23523625332403125, 'batch_size': 16}\n",
      "Epoch 1/50\n",
      "144/144 [==============================] - 5s 14ms/step - loss: 1.7282 - accuracy: 0.3420 - val_loss: 1.4556 - val_accuracy: 0.4653\n",
      "Epoch 2/50\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.4369 - accuracy: 0.4770 - val_loss: 1.3333 - val_accuracy: 0.5122\n",
      "Epoch 3/50\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2603 - accuracy: 0.5330 - val_loss: 1.2241 - val_accuracy: 0.5434\n",
      "Epoch 4/50\n",
      "144/144 [==============================] - 1s 10ms/step - loss: 1.1671 - accuracy: 0.5712 - val_loss: 1.1214 - val_accuracy: 0.6024\n",
      "Epoch 5/50\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0441 - accuracy: 0.6202 - val_loss: 1.0378 - val_accuracy: 0.6146\n",
      "Epoch 6/50\n",
      "144/144 [==============================] - 1s 10ms/step - loss: 0.9419 - accuracy: 0.6541 - val_loss: 1.0365 - val_accuracy: 0.6198\n",
      "Epoch 7/50\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.8539 - accuracy: 0.6853 - val_loss: 0.8581 - val_accuracy: 0.6840\n",
      "Epoch 8/50\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.7736 - accuracy: 0.7287 - val_loss: 0.8691 - val_accuracy: 0.6962\n",
      "Epoch 9/50\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.6613 - accuracy: 0.7604 - val_loss: 0.7811 - val_accuracy: 0.7431\n",
      "Epoch 10/50\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.5950 - accuracy: 0.7869 - val_loss: 0.6955 - val_accuracy: 0.7691\n",
      "Epoch 11/50\n",
      "144/144 [==============================] - 2s 10ms/step - loss: 0.5225 - accuracy: 0.8147 - val_loss: 0.6711 - val_accuracy: 0.7656\n",
      "Epoch 12/50\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.4823 - accuracy: 0.8442 - val_loss: 0.6211 - val_accuracy: 0.7882\n",
      "Epoch 13/50\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.4145 - accuracy: 0.8542 - val_loss: 0.5709 - val_accuracy: 0.8264\n",
      "Epoch 14/50\n",
      "144/144 [==============================] - 2s 10ms/step - loss: 0.3497 - accuracy: 0.8763 - val_loss: 0.5299 - val_accuracy: 0.8438\n",
      "Epoch 15/50\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.3268 - accuracy: 0.8937 - val_loss: 0.4577 - val_accuracy: 0.8872\n",
      "Epoch 16/50\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.2890 - accuracy: 0.8971 - val_loss: 0.4166 - val_accuracy: 0.8854\n",
      "Epoch 17/50\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.2700 - accuracy: 0.9089 - val_loss: 0.4593 - val_accuracy: 0.8854\n",
      "Epoch 18/50\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.2619 - accuracy: 0.9128 - val_loss: 0.4792 - val_accuracy: 0.8819\n",
      "Epoch 19/50\n",
      "144/144 [==============================] - 2s 14ms/step - loss: 0.2056 - accuracy: 0.9353 - val_loss: 0.4324 - val_accuracy: 0.9097\n",
      "Epoch 20/50\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.2474 - accuracy: 0.9171 - val_loss: 0.4644 - val_accuracy: 0.8837\n",
      "Epoch 21/50\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.2051 - accuracy: 0.9327 - val_loss: 0.3975 - val_accuracy: 0.9115\n",
      "Epoch 22/50\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.1694 - accuracy: 0.9427 - val_loss: 0.4275 - val_accuracy: 0.9271\n",
      "Epoch 23/50\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.1593 - accuracy: 0.9453 - val_loss: 0.4304 - val_accuracy: 0.8993\n",
      "Epoch 24/50\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.1550 - accuracy: 0.9466 - val_loss: 0.4674 - val_accuracy: 0.9045\n",
      "Epoch 25/50\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.1667 - accuracy: 0.9423 - val_loss: 0.4285 - val_accuracy: 0.8958\n",
      "Epoch 26/50\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.1259 - accuracy: 0.9592 - val_loss: 0.4021 - val_accuracy: 0.9097\n",
      "18/18 [==============================] - 1s 6ms/step - loss: 0.3975 - accuracy: 0.9115\n",
      "Final Test Loss: 0.3975, Test Accuracy: 91.15%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import opensmile\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import optuna\n",
    "\n",
    "# Load Data for RAVDESS (recursive)\n",
    "def load_audio_files_ravdess(dataset_path):\n",
    "    audio_files = []\n",
    "    labels = []\n",
    "    for root, _, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                emotion_code = int(file.split(\"-\")[2])  # Extract emotion from filename\n",
    "                labels.append(emotion_code)\n",
    "                audio_files.append(os.path.join(root, file))\n",
    "    print(f\"Found {len(audio_files)} audio files in total.\")\n",
    "    return audio_files, labels\n",
    "\n",
    "# Emotion Mapping for RAVDESS\n",
    "def map_emotions_ravdess(labels):\n",
    "    emotion_dict = {\n",
    "        1: 'neutral', 2: 'calm', 3: 'happy', 4: 'sad',\n",
    "        5: 'angry', 6: 'fearful', 7: 'disgust', 8: 'surprised'\n",
    "    }\n",
    "    return [emotion_dict[label] for label in labels]\n",
    "\n",
    "# Feature Extraction using OpenSMILE\n",
    "def extract_features(file_path):\n",
    "    smile = opensmile.Smile(\n",
    "        feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "        feature_level=opensmile.FeatureLevel.Functionals\n",
    "    )\n",
    "    features = smile.process_file(file_path)\n",
    "    return features.values.flatten()\n",
    "\n",
    "# Feature Selection using XGBoost\n",
    "def feature_selection(X, y):\n",
    "    xgb_model = xgb.XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss')\n",
    "    xgb_model.fit(X, y)\n",
    "    feature_importances = xgb_model.feature_importances_\n",
    "    top_features = np.argsort(feature_importances)[-50:]\n",
    "    return X[:, top_features]\n",
    "\n",
    "# --------- Load and Process RAVDESS Dataset ---------\n",
    "dataset_path = \"C:/Users/samhi/OneDrive/문서/College/s6/Speech Processing/Endsem/Final codes/ravdees\"  # Update if needed\n",
    "\n",
    "audio_files, labels = load_audio_files_ravdess(dataset_path)\n",
    "labels_mapped = map_emotions_ravdess(labels)\n",
    "\n",
    "# Robust Feature Extraction\n",
    "X = []\n",
    "y_clean = []\n",
    "failed_files = []\n",
    "\n",
    "for file, label in tqdm(zip(audio_files, labels_mapped), total=len(audio_files)):\n",
    "    try:\n",
    "        features = extract_features(file)\n",
    "        if features.size == 0:\n",
    "            raise ValueError(\"Empty feature vector\")\n",
    "        X.append(features)\n",
    "        y_clean.append(label)\n",
    "    except Exception as e:\n",
    "        failed_files.append((file, str(e)))\n",
    "\n",
    "print(f\"Extracted features from {len(X)} files.\")\n",
    "print(f\"Skipped {len(failed_files)} files due to errors.\")\n",
    "\n",
    "# Convert and preprocess\n",
    "X = np.array(X)\n",
    "y = LabelEncoder().fit_transform(y_clean)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_selected = feature_selection(X, y)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optuna Objective Function\n",
    "def objective(trial):\n",
    "    filters_1 = trial.suggest_int('filters_1', 32, 128)\n",
    "    filters_2 = trial.suggest_int('filters_2', 64, 256)\n",
    "    kernel_size = trial.suggest_int('kernel_size', 3, 7)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv1D(filters_1, kernel_size=kernel_size, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(dropout_rate),\n",
    "        Conv1D(filters_2, kernel_size=kernel_size, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(dropout_rate),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(len(set(y)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train.reshape(-1, X_train.shape[1], 1), y_train,\n",
    "        epochs=20, batch_size=batch_size,\n",
    "        validation_data=(X_test.reshape(-1, X_test.shape[1], 1), y_test),\n",
    "        callbacks=[early_stopping], verbose=0\n",
    "    )\n",
    "\n",
    "    _, accuracy = model.evaluate(X_test.reshape(-1, X_test.shape[1], 1), y_test, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "# Run Optuna Optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Best Params\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Final Model Training\n",
    "model = Sequential([\n",
    "    Conv1D(best_params['filters_1'], kernel_size=best_params['kernel_size'], activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(best_params['dropout_rate']),\n",
    "    Conv1D(best_params['filters_2'], kernel_size=best_params['kernel_size'], activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(best_params['dropout_rate']),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(best_params['dropout_rate']),\n",
    "    Dense(len(set(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(\n",
    "    X_train.reshape(-1, X_train.shape[1], 1), y_train,\n",
    "    epochs=50, batch_size=best_params['batch_size'],\n",
    "    validation_data=(X_test.reshape(-1, X_test.shape[1], 1), y_test),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Final Evaluation\n",
    "eval_result = model.evaluate(X_test.reshape(-1, X_test.shape[1], 1), y_test)\n",
    "print(f\"Final Test Loss: {eval_result[0]:.4f}, Test Accuracy: {eval_result[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step\n",
      "Final Test Loss: 0.3975\n",
      "Test Accuracy: 91.15%\n",
      "Macro F1 Score: 0.9105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Predict class probabilities\n",
    "y_pred_probs = model.predict(X_test.reshape(-1, X_test.shape[1], 1))\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Compute F1 Score\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print final evaluation results\n",
    "print(f\"Final Test Loss: {eval_result[0]:.4f}\")\n",
    "print(f\"Test Accuracy: {eval_result[1]*100:.2f}%\")\n",
    "print(f\"Macro F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
